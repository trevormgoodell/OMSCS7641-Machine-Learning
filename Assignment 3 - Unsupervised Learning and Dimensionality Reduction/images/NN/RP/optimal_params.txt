activation: relu
solver: adam
alpha: 0.001
hidden_layer_sizes: (100, 50)
