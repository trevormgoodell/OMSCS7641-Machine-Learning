For the credit dataset, I started with the same SVC as mentioned in the wine dataset, and this time it resulted in an accuracy of 0.75 and an f1-score of 0.83. These results are quite surprising. Usually, if you used the same classifier on the wine dataset and the credit dataset, you would see wildly different results. However, this learning algorithm seemed to perform just as well on both. Also similarly to the wine dataset, the learning curve is very flat, which is also odd for this dataset. This shows how powerful the RBF kernel really is, trying out this kernel as the distance metric in k-NN would be very interesting. 

To see how optimizing this kernel would increase perform, I ran the same GridSearch over C and $\gamma$ as in the wine dataset, and this resulted in a C of 1000 and a $\gamma$ of 0.0001, a much larger C and smaller $\gamma$. This is not too surprising however. C is used to limit overfitting, and as we've seen in other results, believing your training set too much can really hinder performance. For $\gamma$, this controls how similar things need to be to be mapped together. Using a very small $\gamma$ forces things to be very close together. With these two parameters, I think the algorithm learned to create a bunch of really small clusters and then was able to separate those. These optimizations resulted in an accuracy of 0.76 and an f1-score of 0.84. This is in-line with the increased performance seen in the wine dataset.

To see how the linear kernel handle this dataset will be interesting. As mentioned previously, the dataset does not behave well at all, it takes a lot of effort to get it to work well for the testing set. However, after searching over the same C range in the wine dataset, this chose a C of 0.1. This seems awfully low for this dataset. However, it resulted in an accuracy of 0.77 and an f1-score of 0.84. This linear kernel actually performed better on the credit dataset than the wine dataset. This is astounding! The linear kernel is the simplest of tricks in the SVM toolkit, yet it managed to perform really well here. 

Finally, for the poly kernel, after performing the GridSearch, it resulted in a C of 1 and a degree of 2. This resulted in an accuracy of 0.75 and an f1-score of 0.84, just slightly better than unoptimized rbf. 

One interesting thing to note is that degree 1 was not an option for the GridSearch in the polynomial kernel. However, both datasets performed worse with the polynomial kernel instead of the linear kernel. This shows how hard it is to find the right way to change your data into a higher dimension can be. 